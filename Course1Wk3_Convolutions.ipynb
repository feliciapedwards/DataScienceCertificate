{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course1Wk3_Convolutions",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feliciapedwards/TensorFlow-with-Laurence-Moroney/blob/master/Course1Wk3_Convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeM_Do6sJA0G",
        "colab_type": "text"
      },
      "source": [
        "Improving our model using Convolutions.\n",
        "For review, lets take a look at our model from last week."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdL9_2zpJMFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6bdfbd7e-9976-479d-b9a8-f2305556f352"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images / 255.0\n",
        "test_images=test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.5024 - acc: 0.8231\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3777 - acc: 0.8644\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3398 - acc: 0.8750\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3117 - acc: 0.8865\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2941 - acc: 0.8914\n",
            "10000/10000 [==============================] - 0s 36us/sample - loss: 0.3639 - acc: 0.8685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV4-M6VRKZdC",
        "colab_type": "text"
      },
      "source": [
        "Our training data has 89% accuracy while our test data has 87% accuracy. How do we improve this? One way is through convolutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NE2WQKsJZDQ",
        "colab_type": "text"
      },
      "source": [
        "Convolutions try to pinpoint specific details of the image that help distinguish them. We add some layers to create convolution before the dense layers. This refines the information that is passed down to the dense layers, hopefully making it more concentrated and focused."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3kMOennKCxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "cf5e63fc-5b94-4eca-9ee4-730acc152f00"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.4411 - acc: 0.8385\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.2964 - acc: 0.8906\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.2496 - acc: 0.9079\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.2189 - acc: 0.9181\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.1928 - acc: 0.9277\n",
            "10000/10000 [==============================] - 4s 402us/sample - loss: 0.2453 - acc: 0.9112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AlwQrR1LYHc",
        "colab_type": "text"
      },
      "source": [
        "Here we had to shape both our training and test data to (60000, 28, 28, 1) and (10000, 28, 28, 1). This is critical, otherwise we'll get an error since the Convolutions wont be able to recognize the shape. \n",
        "\n",
        "The first layer \"tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1))\" in our model instructs keras to generate 64 filters. These filters are 3 by 3, their activation is relu, which means we only keep our 0 or larger values, and  the input shape 28 by 28 is maintained. Since our images are gray scale, we use \"1\" for a single byte for color depth.\n",
        "\n",
        "The second layer \"tf.keras.layers.MaxPooling2D(2, 2),\" creates a pooling layer. It's called a max-pooling because we're taking the maximum value. We're specifying a two-by-two pool, so for every four pixels, the largest value will be the values that is passed on. This reduces the image size by a quarter.\n",
        "\n",
        "The second and third layer are created so that the network can learn an additional set of convolutions, and we pool again to reduce the size again. So when all is said and done, the images have been quartered twice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnT2V0jYjUXi",
        "colab_type": "text"
      },
      "source": [
        "The train data accuracy is 93% and the test data accuracy is 91%. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b45wJD75jLJ",
        "colab_type": "text"
      },
      "source": [
        "Lets change the number of convolutons from 64 to 32 and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QK2-XX15fmZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "f7124bb7-3fd5-4689-f273-3900b19424ed"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               102528    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 113,386\n",
            "Trainable params: 113,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 44s 727us/sample - loss: 0.4804 - acc: 0.8239\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 44s 733us/sample - loss: 0.3193 - acc: 0.8835\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 44s 733us/sample - loss: 0.2715 - acc: 0.8995\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 44s 731us/sample - loss: 0.2416 - acc: 0.9119\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 44s 726us/sample - loss: 0.2175 - acc: 0.9196\n",
            "10000/10000 [==============================] - 2s 239us/sample - loss: 0.2801 - acc: 0.8957\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}